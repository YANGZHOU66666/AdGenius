# 记录

本文档为项目的记录文档

## 项目启动

本项目旨在使用SFT+GRPO训练一个LLM，帮助“原素方程”品牌构建一个品牌专属的、能够自动化生成高质量营销文案的AI助手。侧重于社交媒体笔记文案、电商描述文案和付费广告文案。

### 原素方程 品牌风格指南
- 品牌理念: 

精简有效，回归肌肤本源。我们专注于科学配方，摒弃不必要的成分堆砌。

- 品牌人格: 

一位冷静、专业、值得信赖的皮肤科医生或科研人员。

- 沟通要点:

专业严谨: 用词准确，逻辑清晰，像在做一次小科普。

冷静客观: 专注于解决方案，不贩卖焦虑，避免使用夸张的感叹句。

透明真诚: 清晰解释核心成分与功效，不使用模糊、神秘的词汇。

- 关键词选用:

鼓励使用: 屏障, 修护, 科学, 精简, 配方, 浓度, 源头, 温和。

坚决避免: 神器, 逆天, 奇迹, 秒杀, 绝绝子, yyds, 家人们。

## 过程记录

1. 前期准备&首次生成：对于给定的产品列表，划分训练集、验证集，每种产品分别构造3大类文案，分为9小类。使用的脚本为`dataset_generate/generate_sft_datasets.py`，使用的prompts位于`sft_gen_prompts.py`。生成`data/sft_dataset_deepseek.jsonl`和`data/val_dataset_deepseek.jsonl`(2025.8.20)
2. 数据清洗：对于首次生成的数据集，存在问题：1. 有不知道为什么会加进去的标签 2. 有的社交媒体笔记过于平淡，缺少人设真实感和故事感。针对这两点进行优化，使用`dataset_generate/sft_clean_prompts.py`的prompt和`dataset_generate/clean_sft_datasets.py`脚本，对数据进行优化，产物为`sft_dataset_cleaned.jsonl`。后续又发现部分广告文案缺少最后的号召部分，又使用`dataset_generate/clean_sft_datasets_cta.py`脚本和`dataset_generate/sft_clean_prompts_cta.py`的prompt进行清洗，添加CTA部分，产物为`data/sft_dataset_cleaned_cta.jsonl`。(2025.8.22&8.31)
3. 构造Benchmark：使用**LLM as a Jugde**，针对三种类型的侧重点构造prompt，位于`judge/judge_prompts.py`。使用大模型，对三种模型在验证集上的输出进行打分。(2025.8.30)
4. 构造奖励模型所需数据：正样本沿用为sft构造的数据。负样本使用50%“削弱文案”（使用弱prompt+弱模型生成方向接近但质量不高的文案）+30%“夸张文案”（故意添加夸大言辞的语料，违背品牌原则）+20%“添加错误”（添加1-2个不实信息）来构造。通过构造这样的负样本，可以让奖励模型对文案文笔不够好、违背品牌初衷和错误的信息进行惩罚。具体的prompts位于`dataset_generate/rm_gen_rej_prompts_exaggerated.py`, `dataset_generate/rm_gen_rej_prompts_fake.py`, `dataset_generate/rm_gen_rej_prompts_weak.py`，脚本为`generate_rm_datasets.py` (2025.8.30)
   由于原始sft_dataset又清洗了（添加了CTA），又将新内容更新到`rm_dataset_updated.csv`（添加CTA后的内容）(2025.8.31)
5. 转换为最终数据格式：从`data/rm_dataset_final.jsonl`转换成`data/sft_dataset_final.jsonl`，换成了hugging face trl库支持的格式(2025.9.1)；
6. SFT训练：采用LoRA，训练模型脚本`sft_trainer.py`，LoRA Adapter合并脚本`merge_adapter.py`，测试验证脚本`sft_tester.py`。(2025.9.1)
