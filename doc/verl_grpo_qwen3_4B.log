ray init kwargs: {'num_cpus': None, 'runtime_env': {'env_vars': {'TOKENIZERS_PARALLELISM': 'true', 'NCCL_DEBUG': 'WARN', 'VLLM_LOGGING_LEVEL': 'WARN', 'VLLM_ALLOW_RUNTIME_LORA_UPDATING': 'true', 'CUDA_DEVICE_MAX_CONNECTIONS': '1'}, 'working_dir': None}}
2025-09-05 03:24:51,042	WARNING utils.py:429 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-09-05 03:24:51,204	INFO worker.py:1942 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=45530)[0m TaskRunner hostname: autodl-container-90e14386db-f048c631, PID: 45530
[36m(TaskRunner pid=45530)[0m {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.FSDPActorConfig',
[36m(TaskRunner pid=45530)[0m                                  'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(TaskRunner pid=45530)[0m                                                 'async_save': False,
[36m(TaskRunner pid=45530)[0m                                                 'load_contents': ['model',
[36m(TaskRunner pid=45530)[0m                                                                   'optimizer',
[36m(TaskRunner pid=45530)[0m                                                                   'extra'],
[36m(TaskRunner pid=45530)[0m                                                 'save_contents': ['model',
[36m(TaskRunner pid=45530)[0m                                                                   'optimizer',
[36m(TaskRunner pid=45530)[0m                                                                   'extra']},
[36m(TaskRunner pid=45530)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=45530)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=45530)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=45530)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=45530)[0m                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=45530)[0m                                  'entropy_coeff': 0,
[36m(TaskRunner pid=45530)[0m                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=45530)[0m                                  'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=45530)[0m                                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=45530)[0m                                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=45530)[0m                                                  'forward_only': False,
[36m(TaskRunner pid=45530)[0m                                                  'forward_prefetch': False,
[36m(TaskRunner pid=45530)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=45530)[0m                                                  'model_dtype': 'fp32',
[36m(TaskRunner pid=45530)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=45530)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=45530)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=45530)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=45530)[0m                                                  'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m                                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                                                  'use_orig_params': False,
[36m(TaskRunner pid=45530)[0m                                                  'use_torch_compile': True,
[36m(TaskRunner pid=45530)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=45530)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=45530)[0m                                  'kl_loss_coef': 0.001,
[36m(TaskRunner pid=45530)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=45530)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=45530)[0m                                  'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',
[36m(TaskRunner pid=45530)[0m                                            'betas': [0.9, 0.999],
[36m(TaskRunner pid=45530)[0m                                            'clip_grad': 1.0,
[36m(TaskRunner pid=45530)[0m                                            'lr': 1e-06,
[36m(TaskRunner pid=45530)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=45530)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=45530)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=45530)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=45530)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=45530)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=45530)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=45530)[0m                                  'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig',
[36m(TaskRunner pid=45530)[0m                                                  'clip_cov_lb': 1.0,
[36m(TaskRunner pid=45530)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(TaskRunner pid=45530)[0m                                                  'clip_cov_ub': 5.0,
[36m(TaskRunner pid=45530)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(TaskRunner pid=45530)[0m                                                  'loss_mode': 'vanilla',
[36m(TaskRunner pid=45530)[0m                                                  'ppo_kl_coef': 0.1},
[36m(TaskRunner pid=45530)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=45530)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=45530)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=45530)[0m                                  'ppo_micro_batch_size_per_gpu': 1,
[36m(TaskRunner pid=45530)[0m                                  'ppo_mini_batch_size': 16,
[36m(TaskRunner pid=45530)[0m                                  'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=45530)[0m                                               'all_ranks': False,
[36m(TaskRunner pid=45530)[0m                                               'enable': False,
[36m(TaskRunner pid=45530)[0m                                               'ranks': [],
[36m(TaskRunner pid=45530)[0m                                               'save_path': 'outputs/profile',
[36m(TaskRunner pid=45530)[0m                                               'tool': None,
[36m(TaskRunner pid=45530)[0m                                               'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                       'analysis': True,
[36m(TaskRunner pid=45530)[0m                                                                       'contents': [],
[36m(TaskRunner pid=45530)[0m                                                                       'discrete': False,
[36m(TaskRunner pid=45530)[0m                                                                       'level': 'level1'},
[36m(TaskRunner pid=45530)[0m                                                               'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                        'discrete': False},
[36m(TaskRunner pid=45530)[0m                                                               'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                         'step_end': None,
[36m(TaskRunner pid=45530)[0m                                                                         'step_start': 0},
[36m(TaskRunner pid=45530)[0m                                                               'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                                'stack_depth': 32,
[36m(TaskRunner pid=45530)[0m                                                                                'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=45530)[0m                                  'shuffle': False,
[36m(TaskRunner pid=45530)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m                                  'tis_imp_ratio_cap': -1,
[36m(TaskRunner pid=45530)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=45530)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=45530)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=45530)[0m                                  'use_remove_padding': False,
[36m(TaskRunner pid=45530)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=45530)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=45530)[0m                        'model': {'_target_': 'verl.workers.config.HFModelConfig',
[36m(TaskRunner pid=45530)[0m                                  'custom_chat_template': None,
[36m(TaskRunner pid=45530)[0m                                  'enable_activation_offload': False,
[36m(TaskRunner pid=45530)[0m                                  'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=45530)[0m                                  'exclude_modules': None,
[36m(TaskRunner pid=45530)[0m                                  'external_lib': None,
[36m(TaskRunner pid=45530)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(TaskRunner pid=45530)[0m                                  'hf_config_path': None,
[36m(TaskRunner pid=45530)[0m                                  'lora_alpha': 16,
[36m(TaskRunner pid=45530)[0m                                  'lora_rank': 0,
[36m(TaskRunner pid=45530)[0m                                  'override_config': {},
[36m(TaskRunner pid=45530)[0m                                  'path': '/root/autodl-tmp/Qwen3-4B-Instruct-2507-final',
[36m(TaskRunner pid=45530)[0m                                  'target_modules': 'all-linear',
[36m(TaskRunner pid=45530)[0m                                  'tokenizer_path': None,
[36m(TaskRunner pid=45530)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=45530)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=45530)[0m                                  'use_liger': False,
[36m(TaskRunner pid=45530)[0m                                  'use_remove_padding': False,
[36m(TaskRunner pid=45530)[0m                                  'use_shm': False},
[36m(TaskRunner pid=45530)[0m                        'nccl_timeout': 600,
[36m(TaskRunner pid=45530)[0m                        'ref': {'entropy_checkpointing': False,
[36m(TaskRunner pid=45530)[0m                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=45530)[0m                                'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=45530)[0m                                                'entropy_checkpointing': False,
[36m(TaskRunner pid=45530)[0m                                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=45530)[0m                                                'forward_only': False,
[36m(TaskRunner pid=45530)[0m                                                'forward_prefetch': False,
[36m(TaskRunner pid=45530)[0m                                                'fsdp_size': -1,
[36m(TaskRunner pid=45530)[0m                                                'model_dtype': 'fp32',
[36m(TaskRunner pid=45530)[0m                                                'offload_policy': False,
[36m(TaskRunner pid=45530)[0m                                                'optimizer_offload': False,
[36m(TaskRunner pid=45530)[0m                                                'param_offload': False,
[36m(TaskRunner pid=45530)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=45530)[0m                                                'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m                                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                                                'use_orig_params': False,
[36m(TaskRunner pid=45530)[0m                                                'use_torch_compile': True,
[36m(TaskRunner pid=45530)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=45530)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=45530)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=45530)[0m                                'log_prob_micro_batch_size_per_gpu': 4,
[36m(TaskRunner pid=45530)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=45530)[0m                                'model': None,
[36m(TaskRunner pid=45530)[0m                                'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=45530)[0m                                             'all_ranks': False,
[36m(TaskRunner pid=45530)[0m                                             'enable': False,
[36m(TaskRunner pid=45530)[0m                                             'ranks': [],
[36m(TaskRunner pid=45530)[0m                                             'save_path': 'outputs/profile',
[36m(TaskRunner pid=45530)[0m                                             'tool': None,
[36m(TaskRunner pid=45530)[0m                                             'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                     'analysis': True,
[36m(TaskRunner pid=45530)[0m                                                                     'contents': [],
[36m(TaskRunner pid=45530)[0m                                                                     'discrete': False,
[36m(TaskRunner pid=45530)[0m                                                                     'level': 'level1'},
[36m(TaskRunner pid=45530)[0m                                                             'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                      'discrete': False},
[36m(TaskRunner pid=45530)[0m                                                             'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                       'step_end': None,
[36m(TaskRunner pid=45530)[0m                                                                       'step_start': 0},
[36m(TaskRunner pid=45530)[0m                                                             'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                              'stack_depth': 32,
[36m(TaskRunner pid=45530)[0m                                                                              'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=45530)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                                'use_torch_compile': True},
[36m(TaskRunner pid=45530)[0m                        'rollout': {'_target_': 'verl.workers.config.RolloutConfig',
[36m(TaskRunner pid=45530)[0m                                    'agent': {'_target_': 'verl.workers.config.AgentLoopConfig',
[36m(TaskRunner pid=45530)[0m                                              'agent_loop_config_path': None,
[36m(TaskRunner pid=45530)[0m                                              'custom_async_server': {'_target_': 'verl.workers.config.CustomAsyncServerConfig',
[36m(TaskRunner pid=45530)[0m                                                                      'name': None,
[36m(TaskRunner pid=45530)[0m                                                                      'path': None},
[36m(TaskRunner pid=45530)[0m                                              'num_workers': 8},
[36m(TaskRunner pid=45530)[0m                                    'calculate_log_probs': False,
[36m(TaskRunner pid=45530)[0m                                    'cudagraph_capture_sizes': None,
[36m(TaskRunner pid=45530)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=45530)[0m                                    'do_sample': True,
[36m(TaskRunner pid=45530)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=45530)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=45530)[0m                                    'enforce_eager': False,
[36m(TaskRunner pid=45530)[0m                                    'engine_kwargs': {'sglang': {}, 'vllm': {}},
[36m(TaskRunner pid=45530)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=45530)[0m                                    'gpu_memory_utilization': 0.4,
[36m(TaskRunner pid=45530)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=45530)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=45530)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=45530)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=45530)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=45530)[0m                                    'log_prob_micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=45530)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=45530)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=45530)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=45530)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=45530)[0m                                    'mode': 'sync',
[36m(TaskRunner pid=45530)[0m                                    'multi_stage_wake_up': False,
[36m(TaskRunner pid=45530)[0m                                    'multi_turn': {'_target_': 'verl.workers.config.MultiTurnConfig',
[36m(TaskRunner pid=45530)[0m                                                   'enable': False,
[36m(TaskRunner pid=45530)[0m                                                   'format': 'hermes',
[36m(TaskRunner pid=45530)[0m                                                   'interaction_config_path': None,
[36m(TaskRunner pid=45530)[0m                                                   'max_assistant_turns': None,
[36m(TaskRunner pid=45530)[0m                                                   'max_parallel_calls': 1,
[36m(TaskRunner pid=45530)[0m                                                   'max_tool_response_length': 256,
[36m(TaskRunner pid=45530)[0m                                                   'max_user_turns': None,
[36m(TaskRunner pid=45530)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(TaskRunner pid=45530)[0m                                                   'tool_config_path': None,
[36m(TaskRunner pid=45530)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(TaskRunner pid=45530)[0m                                                   'use_inference_chat_template': False},
[36m(TaskRunner pid=45530)[0m                                    'n': 4,
[36m(TaskRunner pid=45530)[0m                                    'name': 'vllm',
[36m(TaskRunner pid=45530)[0m                                    'over_sample_rate': 0,
[36m(TaskRunner pid=45530)[0m                                    'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=45530)[0m                                                 'all_ranks': False,
[36m(TaskRunner pid=45530)[0m                                                 'enable': False,
[36m(TaskRunner pid=45530)[0m                                                 'ranks': [],
[36m(TaskRunner pid=45530)[0m                                                 'save_path': 'outputs/profile',
[36m(TaskRunner pid=45530)[0m                                                 'tool': None,
[36m(TaskRunner pid=45530)[0m                                                 'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                         'analysis': True,
[36m(TaskRunner pid=45530)[0m                                                                         'contents': [],
[36m(TaskRunner pid=45530)[0m                                                                         'discrete': False,
[36m(TaskRunner pid=45530)[0m                                                                         'level': 'level1'},
[36m(TaskRunner pid=45530)[0m                                                                 'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                          'discrete': False},
[36m(TaskRunner pid=45530)[0m                                                                 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                           'step_end': None,
[36m(TaskRunner pid=45530)[0m                                                                           'step_start': 0},
[36m(TaskRunner pid=45530)[0m                                                                 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                                  'stack_depth': 32,
[36m(TaskRunner pid=45530)[0m                                                                                  'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=45530)[0m                                    'prompt_length': 256,
[36m(TaskRunner pid=45530)[0m                                    'response_length': 512,
[36m(TaskRunner pid=45530)[0m                                    'skip_dump_dir': '/tmp/rollout_dump',
[36m(TaskRunner pid=45530)[0m                                    'skip_rollout': False,
[36m(TaskRunner pid=45530)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=45530)[0m                                    'tensor_model_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                                    'top_k': -1,
[36m(TaskRunner pid=45530)[0m                                    'top_p': 1,
[36m(TaskRunner pid=45530)[0m                                    'trace': {'_target_': 'verl.workers.config.TraceConfig',
[36m(TaskRunner pid=45530)[0m                                              'backend': None,
[36m(TaskRunner pid=45530)[0m                                              'token2text': False},
[36m(TaskRunner pid=45530)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(TaskRunner pid=45530)[0m                                    'val_kwargs': {'_target_': 'verl.workers.config.SamplingConfig',
[36m(TaskRunner pid=45530)[0m                                                   'do_sample': False,
[36m(TaskRunner pid=45530)[0m                                                   'n': 1,
[36m(TaskRunner pid=45530)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=45530)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=45530)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=45530)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(TaskRunner pid=45530)[0m                'adv_estimator': 'grpo',
[36m(TaskRunner pid=45530)[0m                'gamma': 1.0,
[36m(TaskRunner pid=45530)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(TaskRunner pid=45530)[0m                            'horizon': 10000,
[36m(TaskRunner pid=45530)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=45530)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=45530)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=45530)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=45530)[0m                'lam': 1.0,
[36m(TaskRunner pid=45530)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=45530)[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},
[36m(TaskRunner pid=45530)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=45530)[0m                'use_pf_ppo': False},
[36m(TaskRunner pid=45530)[0m  'critic': {'_target_': 'verl.workers.config.FSDPCriticConfig',
[36m(TaskRunner pid=45530)[0m             'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(TaskRunner pid=45530)[0m                            'async_save': False,
[36m(TaskRunner pid=45530)[0m                            'load_contents': ['model', 'optimizer', 'extra'],
[36m(TaskRunner pid=45530)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=45530)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=45530)[0m             'enable': None,
[36m(TaskRunner pid=45530)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=45530)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=45530)[0m             'forward_micro_batch_size_per_gpu': 4,
[36m(TaskRunner pid=45530)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=45530)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=45530)[0m             'model': {'_target_': 'verl.workers.config.FSDPCriticModelCfg',
[36m(TaskRunner pid=45530)[0m                       'enable_activation_offload': False,
[36m(TaskRunner pid=45530)[0m                       'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=45530)[0m                       'external_lib': None,
[36m(TaskRunner pid=45530)[0m                       'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=45530)[0m                                       'entropy_checkpointing': False,
[36m(TaskRunner pid=45530)[0m                                       'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=45530)[0m                                       'forward_only': False,
[36m(TaskRunner pid=45530)[0m                                       'forward_prefetch': False,
[36m(TaskRunner pid=45530)[0m                                       'fsdp_size': -1,
[36m(TaskRunner pid=45530)[0m                                       'model_dtype': 'fp32',
[36m(TaskRunner pid=45530)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=45530)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=45530)[0m                                       'param_offload': False,
[36m(TaskRunner pid=45530)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=45530)[0m                                       'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m                                       'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                                       'use_orig_params': False,
[36m(TaskRunner pid=45530)[0m                                       'use_torch_compile': True,
[36m(TaskRunner pid=45530)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=45530)[0m                       'lora_alpha': 16,
[36m(TaskRunner pid=45530)[0m                       'lora_rank': 0,
[36m(TaskRunner pid=45530)[0m                       'override_config': {},
[36m(TaskRunner pid=45530)[0m                       'path': '/root/autodl-tmp/Qwen3-4B-Instruct-2507',
[36m(TaskRunner pid=45530)[0m                       'target_modules': 'all-linear',
[36m(TaskRunner pid=45530)[0m                       'tokenizer_path': '/root/autodl-tmp/Qwen3-4B-Instruct-2507-final',
[36m(TaskRunner pid=45530)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=45530)[0m                       'use_remove_padding': False,
[36m(TaskRunner pid=45530)[0m                       'use_shm': False},
[36m(TaskRunner pid=45530)[0m             'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',
[36m(TaskRunner pid=45530)[0m                       'betas': [0.9, 0.999],
[36m(TaskRunner pid=45530)[0m                       'clip_grad': 1.0,
[36m(TaskRunner pid=45530)[0m                       'lr': 1e-05,
[36m(TaskRunner pid=45530)[0m                       'lr_warmup_steps': -1,
[36m(TaskRunner pid=45530)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=45530)[0m                       'min_lr_ratio': 0.0,
[36m(TaskRunner pid=45530)[0m                       'num_cycles': 0.5,
[36m(TaskRunner pid=45530)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=45530)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=45530)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=45530)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=45530)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=45530)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=45530)[0m             'ppo_micro_batch_size_per_gpu': 4,
[36m(TaskRunner pid=45530)[0m             'ppo_mini_batch_size': 16,
[36m(TaskRunner pid=45530)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=45530)[0m                          'all_ranks': False,
[36m(TaskRunner pid=45530)[0m                          'enable': False,
[36m(TaskRunner pid=45530)[0m                          'ranks': [],
[36m(TaskRunner pid=45530)[0m                          'save_path': 'outputs/profile',
[36m(TaskRunner pid=45530)[0m                          'tool': None,
[36m(TaskRunner pid=45530)[0m                          'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=45530)[0m                                                  'analysis': True,
[36m(TaskRunner pid=45530)[0m                                                  'contents': [],
[36m(TaskRunner pid=45530)[0m                                                  'discrete': False,
[36m(TaskRunner pid=45530)[0m                                                  'level': 'level1'},
[36m(TaskRunner pid=45530)[0m                                          'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=45530)[0m                                                   'discrete': False},
[36m(TaskRunner pid=45530)[0m                                          'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=45530)[0m                                                    'step_end': None,
[36m(TaskRunner pid=45530)[0m                                                    'step_start': 0},
[36m(TaskRunner pid=45530)[0m                                          'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=45530)[0m                                                           'stack_depth': 32,
[36m(TaskRunner pid=45530)[0m                                                           'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=45530)[0m             'rollout_n': 4,
[36m(TaskRunner pid=45530)[0m             'shuffle': False,
[36m(TaskRunner pid=45530)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=45530)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=45530)[0m  'data': {'apply_chat_template_kwargs': {},
[36m(TaskRunner pid=45530)[0m           'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=45530)[0m           'datagen': {'name': None, 'path': None},
[36m(TaskRunner pid=45530)[0m           'dataloader_num_workers': 8,
[36m(TaskRunner pid=45530)[0m           'filter_overlong_prompts': False,
[36m(TaskRunner pid=45530)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=45530)[0m           'image_key': 'images',
[36m(TaskRunner pid=45530)[0m           'max_prompt_length': 256,
[36m(TaskRunner pid=45530)[0m           'max_response_length': 512,
[36m(TaskRunner pid=45530)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=45530)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=45530)[0m           'return_multi_modal_inputs': True,
[36m(TaskRunner pid=45530)[0m           'return_raw_chat': True,
[36m(TaskRunner pid=45530)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=45530)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=45530)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(TaskRunner pid=45530)[0m           'shuffle': True,
[36m(TaskRunner pid=45530)[0m           'tokenizer': None,
[36m(TaskRunner pid=45530)[0m           'train_batch_size': 256,
[36m(TaskRunner pid=45530)[0m           'train_files': '/root/data/style_imitation/sft_dataset_final.parquet',
[36m(TaskRunner pid=45530)[0m           'truncation': 'error',
[36m(TaskRunner pid=45530)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=45530)[0m           'use_shm': False,
[36m(TaskRunner pid=45530)[0m           'val_batch_size': None,
[36m(TaskRunner pid=45530)[0m           'val_files': '/root/data/style_imitation/val_dataset_final.parquet',
[36m(TaskRunner pid=45530)[0m           'validation_shuffle': False,
[36m(TaskRunner pid=45530)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=45530)[0m  'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=45530)[0m                      'global_tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=45530)[0m                                                      'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=45530)[0m                                                                                    'cuda-memory-usage': 'true',
[36m(TaskRunner pid=45530)[0m                                                                                    'trace': 'cuda,nvtx,cublas,ucx'},
[36m(TaskRunner pid=45530)[0m                                                      'discrete': False,
[36m(TaskRunner pid=45530)[0m                                                      'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(TaskRunner pid=45530)[0m                                                                                'capture-range-end': None,
[36m(TaskRunner pid=45530)[0m                                                                                'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=45530)[0m                                                                                'cuda-memory-usage': 'true',
[36m(TaskRunner pid=45530)[0m                                                                                'kill': 'none',
[36m(TaskRunner pid=45530)[0m                                                                                'trace': 'cuda,nvtx,cublas,ucx'}},
[36m(TaskRunner pid=45530)[0m                                             'torch_memory': {'context': 'all',
[36m(TaskRunner pid=45530)[0m                                                              'kw_args': {},
[36m(TaskRunner pid=45530)[0m                                                              'stack_depth': 32,
[36m(TaskRunner pid=45530)[0m                                                              'stacks': 'all',
[36m(TaskRunner pid=45530)[0m                                                              'trace_alloc_max_entries': 100000}},
[36m(TaskRunner pid=45530)[0m                      'profile_continuous_steps': False,
[36m(TaskRunner pid=45530)[0m                      'save_path': 'outputs/profile',
[36m(TaskRunner pid=45530)[0m                      'steps': None,
[36m(TaskRunner pid=45530)[0m                      'tool': None},
[36m(TaskRunner pid=45530)[0m  'ray_kwargs': {'ray_init': {'num_cpus': None}, 'timeline_json_file': None},
[36m(TaskRunner pid=45530)[0m  'reward_model': {'enable': True,
[36m(TaskRunner pid=45530)[0m                   'enable_resource_pool': False,
[36m(TaskRunner pid=45530)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=45530)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=45530)[0m                   'max_length': None,
[36m(TaskRunner pid=45530)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=45530)[0m                   'micro_batch_size_per_gpu': 8,
[36m(TaskRunner pid=45530)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=45530)[0m                             'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=45530)[0m                                             'forward_prefetch': False,
[36m(TaskRunner pid=45530)[0m                                             'fsdp_size': -1,
[36m(TaskRunner pid=45530)[0m                                             'param_offload': False,
[36m(TaskRunner pid=45530)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=45530)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=45530)[0m                             'input_tokenizer': '/root/autodl-tmp/Qwen3-4B-Instruct-2507-final',
[36m(TaskRunner pid=45530)[0m                             'path': '/root/autodl-tmp/Skywork-Reward-V2-Qwen3-4B-finetuned',
[36m(TaskRunner pid=45530)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=45530)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=45530)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=45530)[0m                             'use_shm': False},
[36m(TaskRunner pid=45530)[0m                   'n_gpus_per_node': 0,
[36m(TaskRunner pid=45530)[0m                   'nnodes': 0,
[36m(TaskRunner pid=45530)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=45530)[0m                                'all_ranks': False,
[36m(TaskRunner pid=45530)[0m                                'enable': False,
[36m(TaskRunner pid=45530)[0m                                'ranks': [],
[36m(TaskRunner pid=45530)[0m                                'save_path': 'outputs/profile',
[36m(TaskRunner pid=45530)[0m                                'tool': None,
[36m(TaskRunner pid=45530)[0m                                'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=45530)[0m                                                        'analysis': True,
[36m(TaskRunner pid=45530)[0m                                                        'contents': [],
[36m(TaskRunner pid=45530)[0m                                                        'discrete': False,
[36m(TaskRunner pid=45530)[0m                                                        'level': 'level1'},
[36m(TaskRunner pid=45530)[0m                                                'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=45530)[0m                                                         'discrete': False},
[36m(TaskRunner pid=45530)[0m                                                'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=45530)[0m                                                          'step_end': None,
[36m(TaskRunner pid=45530)[0m                                                          'step_start': 0},
[36m(TaskRunner pid=45530)[0m                                                'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',
[36m(TaskRunner pid=45530)[0m                                                                 'stack_depth': 32,
[36m(TaskRunner pid=45530)[0m                                                                 'trace_alloc_max_entries': 100000}}},
[36m(TaskRunner pid=45530)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=45530)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(TaskRunner pid=45530)[0m                                      'memory_limit_mb': 1024,
[36m(TaskRunner pid=45530)[0m                                      'url': None},
[36m(TaskRunner pid=45530)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=45530)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=45530)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=45530)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=45530)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=45530)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=45530)[0m              'default_local_dir': 'checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo',
[36m(TaskRunner pid=45530)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=45530)[0m              'device': 'cuda',
[36m(TaskRunner pid=45530)[0m              'esi_redundant_time': 0,
[36m(TaskRunner pid=45530)[0m              'experiment_name': 'qwen3_4b_grpo',
[36m(TaskRunner pid=45530)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=45530)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=45530)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=45530)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=45530)[0m              'n_gpus_per_node': 2,
[36m(TaskRunner pid=45530)[0m              'nnodes': 1,
[36m(TaskRunner pid=45530)[0m              'project_name': 'verl_grpo_elemental_equation',
[36m(TaskRunner pid=45530)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=45530)[0m              'resume_from_path': None,
[36m(TaskRunner pid=45530)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=45530)[0m              'rollout_data_dir': None,
[36m(TaskRunner pid=45530)[0m              'save_freq': 1,
[36m(TaskRunner pid=45530)[0m              'test_freq': 1,
[36m(TaskRunner pid=45530)[0m              'total_epochs': 1,
[36m(TaskRunner pid=45530)[0m              'total_training_steps': None,
[36m(TaskRunner pid=45530)[0m              'use_legacy_worker_impl': 'auto',
[36m(TaskRunner pid=45530)[0m              'val_before_train': False,
[36m(TaskRunner pid=45530)[0m              'val_only': False,
[36m(TaskRunner pid=45530)[0m              'validation_data_dir': None}}
[36m(TaskRunner pid=45530)[0m /root/autodl-tmp/verl/verl/trainer/main_ppo.py:255: UserWarning: Disabled critic as algorithm.adv_estimator != gae. If it is not intended, please set critic.enable=True
[36m(TaskRunner pid=45530)[0m   use_critic=need_critic(config),
[36m(TaskRunner pid=45530)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=45530)[0m /root/autodl-tmp/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(TaskRunner pid=45530)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(TaskRunner pid=45530)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=45530)[0m dataset len: 612
[36m(TaskRunner pid=45530)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=45530)[0m dataset len: 170
[36m(TaskRunner pid=45530)[0m Size of train dataloader: 2, Size of val dataloader: 1
[36m(TaskRunner pid=45530)[0m Total training steps: 2
[36m(TaskRunner pid=45530)[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>
[36m(TaskRunner pid=45530)[0m /root/autodl-tmp/verl/verl/trainer/ppo/ray_trainer.py:339: UserWarning: Disabled critic as algorithm.adv_estimator != gae. If it is not intended, please set critic.enable=True
[36m(TaskRunner pid=45530)[0m   self.use_critic = need_critic(self.config)
[36m(WorkerDict pid=45978)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards:   0%|                                                                                                                                     | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                             | 1/4 [00:00<00:01,  1.52it/s]
[36m(WorkerDict pid=45977)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=45977)[0m Loading checkpoint shards:   0%|                                                                                                                                     | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 3/4 [00:05<00:02,  2.51s/it][32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=45978)[0m Skipping monkey patch for Qwen3ForTokenClassification as use_fused_kernels is False or fused_kernels_backend is None
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.97s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.40s/it]
[36m(WorkerDict pid=45978)[0m Some weights of Qwen3ForTokenClassification were not initialized from the model checkpoint at /root/autodl-tmp/Skywork-Reward-V2-Qwen3-4B-finetuned and are newly initialized: ['score.bias']
[36m(WorkerDict pid=45978)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=45977)[0m NCCL version 2.21.5+cuda12.4
[36m(WorkerDict pid=45977)[0m Model config after override: Qwen3Config {
[36m(WorkerDict pid=45977)[0m   "architectures": [
[36m(WorkerDict pid=45977)[0m     "Qwen3ForCausalLM"
[36m(WorkerDict pid=45977)[0m   ],
[36m(WorkerDict pid=45977)[0m   "attention_bias": false,
[36m(WorkerDict pid=45977)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=45977)[0m   "dtype": "bfloat16",
[36m(WorkerDict pid=45977)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=45977)[0m   "head_dim": 128,
[36m(WorkerDict pid=45977)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=45977)[0m   "hidden_size": 2560,
[36m(WorkerDict pid=45977)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=45977)[0m   "intermediate_size": 9728,
[36m(WorkerDict pid=45977)[0m   "layer_types": [
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention",
[36m(WorkerDict pid=45977)[0m     "full_attention"
[36m(WorkerDict pid=45977)[0m   ],
[36m(WorkerDict pid=45977)[0m   "max_position_embeddings": 262144,
[36m(WorkerDict pid=45977)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=45977)[0m   "model_type": "qwen3",
[36m(WorkerDict pid=45977)[0m   "num_attention_heads": 32,
[36m(WorkerDict pid=45977)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=45977)[0m   "num_key_value_heads": 8,
[36m(WorkerDict pid=45977)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=45977)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=45977)[0m   "rope_scaling": null,
[36m(WorkerDict pid=45977)[0m   "rope_theta": 5000000,
[36m(WorkerDict pid=45977)[0m   "sliding_window": null,
[36m(WorkerDict pid=45977)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=45977)[0m   "transformers_version": "4.51.1",
[36m(WorkerDict pid=45977)[0m   "use_cache": true,
[36m(WorkerDict pid=45977)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=45977)[0m   "vocab_size": 151936
[36m(WorkerDict pid=45977)[0m }
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m Skipping monkey patch for Qwen3ForTokenClassification as use_fused_kernels is False or fused_kernels_backend is None
[36m(WorkerDict pid=45977)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen3ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=45977)[0m Loading checkpoint shards:   0%|                                                                                                                                     | 0/2 [00:00<?, ?it/s]
[36m(WorkerDict pid=45977)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 3/4 [00:06<00:02,  2.51s/it]
[36m(WorkerDict pid=45977)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.94s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.41s/it]
[36m(WorkerDict pid=45977)[0m Some weights of Qwen3ForTokenClassification were not initialized from the model checkpoint at /root/autodl-tmp/Skywork-Reward-V2-Qwen3-4B-finetuned and are newly initialized: ['score.bias']
[36m(WorkerDict pid=45977)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=45977)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                              | 1/2 [00:06<00:06,  6.40s/it]
[36m(WorkerDict pid=45978)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen3ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards:   0%|                                                                                                                                     | 0/2 [00:00<?, ?it/s]
[36m(WorkerDict pid=45977)[0m Skipping monkey patch for Qwen3ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=45977)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.74s/it]
[36m(WorkerDict pid=45977)[0m Qwen3ForCausalLM contains 4.02B parameters
[36m(WorkerDict pid=45977)[0m wrap_policy: functools.partial(<function _or_policy at 0x7f3d74378af0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x7f3d743789d0>, transformer_layer_cls={<class 'transformers.models.qwen3.modeling_qwen3.Qwen3DecoderLayer'>})])
[36m(WorkerDict pid=45977)[0m Total steps: 2, num_warmup_steps: 0
[36m(WorkerDict pid=45977)[0m Actor use_remove_padding=False
[36m(WorkerDict pid=45977)[0m Actor use_fused_kernels=False
[36m(WorkerDict pid=45978)[0m Skipping monkey patch for Qwen3ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=45978)[0m /root/autodl-tmp/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=45978)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                              | 1/2 [00:06<00:06,  6.36s/it]
[36m(WorkerDict pid=45978)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.69s/it]
[36m(WorkerDict pid=45978)[0m WARNING 09-05 03:25:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f2e46612140>
[36m(WorkerDict pid=45977)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 512, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=45977)[0m WARNING 09-05 03:25:54 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f21fc7161a0>
[36m(WorkerDict pid=45977)[0m /root/autodl-tmp/conda_envs/verl_env/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=45977)[0m   warnings.warn(
[36m(WorkerDict pid=45977)[0m /root/autodl-tmp/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=45977)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(TaskRunner pid=45530)[0m wandb: Tracking run with wandb version 0.21.3
[36m(TaskRunner pid=45530)[0m wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(TaskRunner pid=45530)[0m wandb: Run data is saved locally in /root/autodl-tmp/verl/wandb/offline-run-20250905_032643-a33qeqqf
[36m(TaskRunner pid=45530)[0m Checkpoint tracker file does not exist: /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/latest_checkpointed_iteration.txt
[36m(TaskRunner pid=45530)[0m Training from scratch
[36m(TaskRunner pid=45530)[0m Training Progress:   0%|                                                                                                                                             | 0/2 [00:00<?, ?it/s]
[36m(WorkerDict pid=45977)[0m Switch template. chat: <|im_start|>user
[36m(WorkerDict pid=45977)[0m è¯·ä¸º"åŽŸç´ æ–¹ç¨‹"å“ç‰Œçš„å¦‚ä¸‹äº§å“åˆ›ä½œä¸€æ¡è¯¦ç»†çš„ç”µå•†å¹³å°äº§å“ä»‹ç»æ–‡æ¡ˆ
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m {"product_name": "ç¾Žç™½ç„•é‡‡ç²¾åŽ", "category": "ç²¾åŽ", "core_ingredients": "çƒŸé…°èƒº, ç»´ç”Ÿç´ C, ç†Šæžœè‹·, ç§¯é›ªè‰æå–ç‰©", "features": "å‡åŒ€è‚¤è‰², æäº®ç¾Žç™½, æ”¹å–„æš—æ²‰", "target_audience": "æ‰€æœ‰è‚¤è´¨, ç‰¹åˆ«æ˜¯è‚¤è‰²ä¸å‡"}<|im_end|>
[36m(WorkerDict pid=45977)[0m <|im_start|>assistant
[36m(WorkerDict pid=45977)[0m <think>
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m </think>
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m ## åŽŸç´ æ–¹ç¨‹ç¾Žç™½ç„•é‡‡ç²¾åŽï¼šç§‘å­¦æäº®ï¼Œå”¤é†’è‚Œè‚¤é€æ˜Žæ„Ÿ
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m **æ ¸å¿ƒé…æ–¹ | ä¸‰å¤§æäº®ååŒ**  
[36m(WorkerDict pid=45977)[0m çƒŸé…°èƒº(10%)ååŒç»´ç”Ÿç´ Cè¡ç”Ÿç‰©ï¼Œç²¾å‡†ä½œç”¨äºŽæš—æ²‰æºå¤´ï¼Œæº¶è§£å·²å½¢æˆè‰²ç´ ï¼›ç†Šæžœè‹·æ¸©å’Œç›¾ç‰Œï¼Œé¢„é˜²é»‘è‰²ç´ ç”Ÿæˆï¼›ç§¯é›ªè‰æå–ç‰©èˆ’ç¼“æŠ—æ°§åŒ–ï¼Œå¼ºåŒ–è‚Œè‚¤å±éšœã€‚ä¸‰é‡æˆåˆ†ç§‘å­¦é…æ¯”ï¼Œå…¼é¡¾é«˜æ•ˆä¸Žæ¸©å’Œã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m **ä¸“ä¸šçªç ´ | 24å°æ—¶ç¾Žç™½æ–¹æ¡ˆ**  
[36m(WorkerDict pid=45977)[0m â–«ï¸æŒç»­æäº®ï¼š4å‘¨å¯å®žçŽ°è‚¤è‰²å‡åŒ€åº¦æå‡38%ï¼ˆç»ä¸´åºŠæµ‹è¯•ï¼‰  
[36m(WorkerDict pid=45977)[0m â–«ï¸æŒ‡çº¹å®žæµ‹ï¼šå¯¹æ¯”å›¾æ˜¾ç¤ºæ¯›å­”æš—æ²‰æ”¹å–„40%ï¼ˆæ•°å­—å¯¹æ¯”å‘ˆçŽ°ï¼‰  
[36m(WorkerDict pid=45977)[0m â–«ï¸æ¸©å’ŒåŠ›æ£€æµ‹ï¼šé€šè¿‡ISO 29030æ•æ„Ÿåˆºæ¿€æµ‹è¯•ï¼Œå­•å¦ˆæ´é¢å³ç”¨
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m **å…¨è‚¤è´¨å®‰å…¨ | åŽŸç´ é˜²æŠ¤ä½“ç³»**  
[36m(WorkerDict pid=45977)[0m - pHå€¼5.5ï¼Œç¬¦åˆè‚Œè‚¤å¼±é…¸çŽ¯å¢ƒ  
[36m(WorkerDict pid=45977)[0m - æ·»åŠ ç¥žç»é…°èƒº3+æž„å»ºä¿æŠ¤è†œ  
[36m(WorkerDict pid=45977)[0m - æ–°åŒ–å­¦ç»“æž„æŠ€æœ¯ï¼ˆä¸“åˆ©å·CN202312345678ï¼‰é¿å…åˆºæ¿€
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m > åŽŸç´ æ–¹ç¨‹ä¸»å¼ ç§‘å­¦ä¸»ä¹‰ï¼šæ¯ä¸€æ»´ç²¾åŽéƒ½ç»æµ“åº¦ä¼˜åŒ–ï¼Œé€šè¿‡ä¸“åˆ©äººå·¥ç¥žç»ç½‘ç»œç­›é€‰æœ‰æ•ˆæˆåˆ†é…æ¯”å…¬å¼ã€‚è¯•ç”¨è£…è£…ï¼ˆ30mlï¼‰çŽ°èµ ï¼Œä¹°å³å‡30å…ƒï¼Œçªç ´å•ä¸€åœºæ™¯åº”ç”¨ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m ðŸ” **å°çº¢ä¹¦å›¾æ–‡ï½œç”¨æˆ·è§†è§’**  
[36m(WorkerDict pid=45977)[0m "ä»Žé’è‰è‰²åˆ°è±¡ç‰™ç™½ï¼Œç»ˆäºŽæ‰¾åˆ°å¹³è¡¡çš„æäº®æ–¹æ¡ˆ" â€”â€”@æ£®å°ä¸ƒçš„åŽŸç´ å®žéªŒå®¤  
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m æ³¨ï¼šæœ¬å“é€šè¿‡ä¸¥æ ¼ç¬¬ä¸‰æ–¹çš®è‚¤ç§‘æµ‹è¯•ï¼Œä¸å«å¯¹ç¾ŸåŸºè‹¯ç”²é…¸é…¯é˜²è…ä½“ç³»ã€‚ç‚¹å‡»å¼€å¯ç²¾å‡†è‚Œè‚¤å˜è“è®¡åˆ’ï¼ŒæŽ¢ç´¢ä¸ªä½“åŒ–æˆåˆ†è§£å†³æ–¹æ¡ˆã€‚<|im_end|>
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45978)[0m kwargs: {'n': 1, 'logprobs': 0, 'max_tokens': 512, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(TaskRunner pid=45530)[0m local_global_step_folder: checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:32:41,418:[Rank 0] Saved model to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/model_world_size_2_rank_0.pt
[36m(WorkerDict pid=45978)[0m /root/autodl-tmp/conda_envs/verl_env/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=45978)[0m   warnings.warn(
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:34:49,652:[Rank 0] Saved optim to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:34:49,655:[Rank 0] Saved extra_state to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=45978)[0m INFO:2025-09-05 03:32:41,489:[Rank 1] Saved model to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:34:49,838:[Rank 0] Saved model config and tokenizer class to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/huggingface
[36m(TaskRunner pid=45530)[0m step:1 - global_seqlen/min:209345 - global_seqlen/max:220020 - global_seqlen/minmax_diff:10675 - global_seqlen/balanced_min:214682 - global_seqlen/balanced_max:214683 - global_seqlen/mean:214682.5 - actor/entropy:3.1008057594299316 - actor/pg_loss:np.float64(0.0012483218053489509) - actor/pg_clipfrac:np.float64(0.007474782632471033) - actor/ppo_kl:np.float64(0.0018580284685176807) - actor/pg_clipfrac_lower:np.float64(0.0) - actor/grad_norm:np.float64(1.9075768068432808) - perf/mfu/actor:np.float64(0.1637369224192165) - perf/max_memory_allocated_gb:np.float64(63.51523780822754) - perf/max_memory_reserved_gb:np.float64(71.013671875) - perf/cpu_memory_used_gb:np.float64(65.55900955200195) - actor/lr:np.float64(1e-06) - training/global_step:1 - training/epoch:0 - critic/score/mean:-23.75 - critic/score/max:62.5 - critic/score/min:-46.25 - critic/rewards/mean:-23.75 - critic/rewards/max:62.5 - critic/rewards/min:-46.25 - critic/advantages/mean:0.004150390625 - critic/advantages/max:1.5078125 - critic/advantages/min:-1.5 - critic/returns/mean:0.004150390625 - critic/returns/max:1.5078125 - critic/returns/min:-1.5 - response_length/mean:305.4541015625 - response_length/max:512.0 - response_length/min:4.0 - response_length/clip_ratio:0.1845703125 - response_length_non_aborted/mean:305.4541015625 - response_length_non_aborted/max:512.0 - response_length_non_aborted/min:4.0 - response_length_non_aborted/clip_ratio:0.1845703125 - response/aborted_ratio:0.0 - prompt_length/mean:113.84765625 - prompt_length/max:126.0 - prompt_length/min:96.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.0004171959590166807 - timing_s/generate_sequences:26.616640090942383 - timing_s/generation_timing/max:27.675107955932617 - timing_s/generation_timing/min:25.55817222595215 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:30.818474574945867 - timing_s/reward:39.393562722951174 - timing_s/old_log_prob:33.65827486105263 - timing_s/adv:0.04222992900758982 - timing_s/update_actor:241.9331648289226 - timing_s/step:345.88848363095894 - timing_s/testing:0.2951527370605618 - timing_s/save_checkpoint:141.18861524993554 - timing_s/stop_profile:6.037997081875801e-05 - timing_per_token_ms/adv:9.835438148798764e-05 - timing_per_token_ms/update_actor:0.5634673641981126 - timing_per_token_ms/gen:0.09852925995474804 - perf/total_num_tokens:429365 - perf/time_per_step:345.88848363095894 - perf/throughput:620.6696960429957
[36m(TaskRunner pid=45530)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                  | 1/2 [08:07<08:07, 487.80s/it]
[36m(WorkerDict pid=45977)[0m Switch template. chat: <|im_start|>user
[36m(WorkerDict pid=45977)[0m è¯·ä¸º"åŽŸç´ æ–¹ç¨‹"å“ç‰Œçš„å¦‚ä¸‹äº§å“åˆ›ä½œä¸€æ¡è¯¦ç»†çš„ç”µå•†å¹³å°äº§å“ä»‹ç»æ–‡æ¡ˆ
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m {"product_name": "ç„•è‚¤æ–°ç”Ÿç²¾åŽ", "category": "ç²¾åŽ", "core_ingredients": "8%ç”˜é†‡é…¸, ä¹³é…¸, æ°´æ¨é…¸, çº¢æ²¡è¯é†‡", "features": "æ¸©å’ŒåŽ»è§’è´¨, æ”¹å–„ç²—ç³™, æäº®è‚¤è‰²", "target_audience": "æ··åˆè‚Œ, æ²¹æ€§è‚Œ è§’è´¨å±‚åŽš"}<|im_end|>
[36m(WorkerDict pid=45977)[0m <|im_start|>assistant
[36m(WorkerDict pid=45977)[0m <think>
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m </think>
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m ### åŽŸç´ æ–¹ç¨‹ ç„•è‚¤æ–°ç”Ÿç²¾åŽ
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m **ç§‘å­¦ç„•è‚¤ï¼Œå‘Šåˆ«ç²—ç³™æš—æ²‰**
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m Experience æœ¬äº§å“ä¸å«åˆºæ¿€æ€§æˆåˆ†ï¼Œä»¥æ¸©å’Œé…æ–¹åº”å¯¹ä¸åŒè‚Œè‚¤éœ€æ±‚ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m #### ä¸ºä»€ä¹ˆé€‰æ‹©â€œç„•è‚¤æ–°ç”Ÿç²¾åŽâ€ï¼Ÿ
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m é¢å¯¹èŠ‚èŠ‚æ”€å‡çš„è‚Œè‚¤å±éšœä¿®å¤æˆæœ¬ï¼Œâ€œç„•è‚¤æ–°ç”Ÿç²¾åŽâ€ä¸ºæ‚¨èµ‹èƒ½ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m - **æ”¹å–„ç²—ç³™å µå¡ž**  
[36m(WorkerDict pid=45977)[0m   8%ç”˜é†‡é…¸ä¸Žä¹³é…¸ååŒä½œç”¨ï¼Œæ·±å…¥æ¯›å­”å±‚æº¶è§£è§’è´¨ï¼Œæ˜¾è‘—ç¼“è§£è‚Œè‚¤ç²—ç³™ã€å µå¡žé—®é¢˜ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m - **æ¸©å’Œæäº®è‚¤è‰²**  
[36m(WorkerDict pid=45977)[0m   æ°´æ¨é…¸æ¸©å’Œæ¸…é™¤è§’æ “ï¼Œçº¢æ²¡è¯é†‡åŒé‡èˆ’ç¼“æ•è‚¤ï¼Œæ”¹å–„åå¤æš—æ²‰ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m - **å®‰å…¨æœ‰æ•ˆé…æ–¹**  
[36m(WorkerDict pid=45977)[0m   ä¸¥æ ¼æŽ§åˆ¶æ´»æ€§ç‰©æ¯”ä¾‹ï¼Œé€‚åˆæ•æ„Ÿè‚Œåˆ†å±‚æ¬¡æ¸…æ´æŠ¤ç†ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m #### é€‚ç”¨äººç¾¤
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m æ··åˆè‚Œ|æ²¹æ€§è‚Œ|è§’è´¨å±‚å¢žåŽšè‚Œè‚¤ï¼Œæ—¥å¸¸ä¿æ´è‚Œè‚¤å±éšœä¿®å¤ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m #### æ¸©é¦¨æç¤º
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m ä½¿ç”¨3é€±å¯è§æ”¹å–„ï¼Œå»ºè®®é…åˆæ¸©å’Œæ´é¢åŽä¸Žä¿æ¹¿ä¹³ä½¿ç”¨ã€‚
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m [ç«‹å³è´­ä¹°](https://m.alibaba.com/product-detail/7u4VQVQVI1Jp8) çŽ°åœ¨æŽŒæ¡ç§‘å­¦å‘µæŠ¤
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m ---
[36m(WorkerDict pid=45977)[0m 
[36m(WorkerDict pid=45977)[0m > *åŽŸç´ æ–¹ç¨‹* åšæŒâ€œç²¾ç®€æœ‰æ•ˆâ€çš„é…æ–¹å“²å­¦ï¼Œå°†æ´»æ€§æˆåˆ†ç²¾ç²¹ç²¾ç®€åˆ°æœ¬è´¨å±‚é¢ã€‚  
[36m(WorkerDict pid=45977)[0m > ä¾æ®ã€ŠNatureã€‹æœŸåˆŠã€Šçš®è‚¤ä»£è°¢è°ƒæŽ§ã€‹ç ”ç©¶ï¼Œ8%ç”˜é†‡é…¸è”åˆä¹³é…¸å¯æå‡è§’è´¨ä»£è°¢æ•ˆçŽ‡37%ã€‚<|im_end|>
[36m(WorkerDict pid=45977)[0m 
[36m(TaskRunner pid=45530)[0m local_global_step_folder: checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:40:30,933:[Rank 0] Saved model to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/model_world_size_2_rank_0.pt
[36m(WorkerDict pid=45978)[0m INFO:2025-09-05 03:34:51,205:[Rank 1] Saved optim to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=45978)[0m INFO:2025-09-05 03:34:51,207:[Rank 1] Saved extra_state to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_1/actor/extra_state_world_size_2_rank_1.pt
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:42:41,100:[Rank 0] Saved optim to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/optim_world_size_2_rank_0.pt
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:42:41,102:[Rank 0] Saved extra_state to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/extra_state_world_size_2_rank_0.pt
[36m(WorkerDict pid=45978)[0m INFO:2025-09-05 03:40:31,264:[Rank 1] Saved model to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/model_world_size_2_rank_1.pt
[36m(WorkerDict pid=45977)[0m INFO:2025-09-05 03:42:41,318:[Rank 0] Saved model config and tokenizer class to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/huggingface
[36m(TaskRunner pid=45530)[0m step:2 - global_seqlen/min:218267 - global_seqlen/max:221379 - global_seqlen/minmax_diff:3112 - global_seqlen/balanced_min:219823 - global_seqlen/balanced_max:219823 - global_seqlen/mean:219823.0 - actor/entropy:2.514495611190796 - actor/pg_loss:np.float64(0.0006542587458966409) - actor/pg_clipfrac:np.float64(0.006605373223464994) - actor/ppo_kl:np.float64(0.0012398534147113338) - actor/pg_clipfrac_lower:np.float64(0.0) - actor/grad_norm:np.float64(1.8908431679010391) - perf/mfu/actor:np.float64(0.17470508115276176) - perf/max_memory_allocated_gb:np.float64(63.51523780822754) - perf/max_memory_reserved_gb:np.float64(72.224609375) - perf/cpu_memory_used_gb:np.float64(68.12660217285156) - actor/lr:np.float64(1e-06) - training/global_step:2 - training/epoch:0 - critic/score/mean:-15.5 - critic/score/max:60.0 - critic/score/min:-45.75 - critic/rewards/mean:-15.5 - critic/rewards/max:60.0 - critic/rewards/min:-45.75 - critic/advantages/mean:0.005462646484375 - critic/advantages/max:1.5078125 - critic/advantages/min:-1.5 - critic/returns/mean:0.005462646484375 - critic/returns/max:1.5078125 - critic/returns/min:-1.5 - response_length/mean:315.974609375 - response_length/max:512.0 - response_length/min:42.0 - response_length/clip_ratio:0.1904296875 - response_length_non_aborted/mean:315.974609375 - response_length_non_aborted/max:512.0 - response_length_non_aborted/min:42.0 - response_length_non_aborted/clip_ratio:0.1904296875 - response/aborted_ratio:0.0 - prompt_length/mean:113.3671875 - prompt_length/max:127.0 - prompt_length/min:95.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:5.126907490193844e-05 - timing_s/generate_sequences:27.5799503326416 - timing_s/generation_timing/max:27.834735870361328 - timing_s/generation_timing/min:27.325164794921875 - timing_s/generation_timing/topk_ratio:0.5 - timing_s/gen:31.746975385118276 - timing_s/reward:31.230291143991053 - timing_s/old_log_prob:33.78679820895195 - timing_s/adv:0.035697226878255606 - timing_s/update_actor:232.259007609915 - timing_s/step:329.1015351880342 - timing_s/testing:0.2965719108469784 - timing_s/save_checkpoint:142.80448957998306 - timing_s/stop_profile:0.0001190889161080122 - timing_per_token_ms/adv:8.119538646605589e-05 - timing_per_token_ms/update_actor:0.5282864113625849 - timing_per_token_ms/gen:0.09811834473299463 - perf/total_num_tokens:439646 - perf/time_per_step:329.1015351880342 - perf/throughput:667.9488744238242
[36m(TaskRunner pid=45530)[0m 'Final validation metrics: {}'
[36m(TaskRunner pid=45530)[0m Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [16:00<00:00, 478.67s/it]Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [16:00<00:00, 480.04s/it]
[36m(WorkerDict pid=45978)[0m INFO:2025-09-05 03:42:43,506:[Rank 1] Saved optim to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/optim_world_size_2_rank_1.pt
[36m(WorkerDict pid=45978)[0m INFO:2025-09-05 03:42:43,509:[Rank 1] Saved extra_state to /root/autodl-tmp/verl/checkpoints/verl_grpo_elemental_equation/qwen3_4b_grpo/global_step_2/actor/extra_state_world_size_2_rank_1.pt
